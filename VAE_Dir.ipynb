{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dirichlet Distribution by VAE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains 9 models I tried to generate Dirichlet Distribution. Model 2 and Model 3 are the best two models so far, but they still have some issues. <br />\n",
    "\n",
    "I will first firstly explain how I generate training datasets, then discuss 9 models with following order: standard VAE, models with comparatively better performance, other models. Each model has result, problem (if applicable), possible reason for problem/success. I will also introduce some models I haven't tried or don't know how to implement.\n",
    "\n",
    "The code is provided in the appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Training Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw 1 sample: <br /> \n",
    "$~~~~~$$\\alpha \\sim$Uniform(0,2) <br /> \n",
    "$~~~~~$generate random samples ($p^{(i)}_1,p^{(i)}_2,p^{(i)}_3$)$\\sim$Dir($\\alpha,\\alpha,\\alpha$), i=1,...,200 <br /> \n",
    "Repeat $10^4$ times and shuffle the whole training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"data1.png\" alt=\"my alt text\" width=300/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw 1 sample: <br /> \n",
    "$~~~~~$($\\alpha_1,\\alpha_2,\\alpha_3$)=(1,1,0.5) <br /> \n",
    "$~~~~~$generate random samples ($p^{(i)}_1,p^{(i)}_2,p^{(i)}_3$)$\\sim$Dir($\\alpha_1,\\alpha_2,\\alpha_3$), i=1,...,200 <br /> \n",
    "Repeat $10^4$ times and shuffle whole training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"data2.png\" alt=\"my alt text\" width=300/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also tried (1,1,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"data3.png\" alt=\"my alt text\" width=300/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix A__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models\n",
    "Current order: standard VAE (Model 1) $\\rightarrow$ models with comparatively better performance (Model 2, 3) $\\rightarrow$ other models (Model 4, 5, 6, 7, 8). <br />\n",
    "\n",
    "Original order: Model 1 $\\rightarrow$ Model 4 $\\rightarrow$ Model 5 $\\rightarrow$ Model 6 $\\rightarrow$ Model 2 $\\rightarrow$ Model 3  $\\rightarrow$ Model 7 $\\rightarrow$ Model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A VAE in standard setting: prior of latent variables is standard multivariant normal distribution. Output layer includes a softmax function. The model is trained by minimizing loss function: <br /> \n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$MSE(p,p$^{\\prime\\prime}$)+KL(Z||N(0,1)) <br /> \n",
    "Detail shown in graphical model below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg1](alg1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg1res1.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(Data 1).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg1res2.png\" alt=\"my alt text\" width=\"300\"/>\n",
    "  <figcaption>(1,1,0.5).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg1res3.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.2).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Problem__: Data generated from this model is too dense. And the more samples trained, the denser datapoints are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible Reason for Result__: this model only learns concentration of training datapoints, and ignores sparsity. See reference https://arxiv.org/abs/1901.02739 for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix B__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with comparatively better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs of above 3 methods are all data, I changed outputs to parameters of Dirichlet Ditribution in this method. Parameter outputs are then used to generate data. Loss function used to train the model is  <br /> $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$MSE(p,p$^{\\prime\\prime}$)+KL(Z||N(0,1)) <br /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg3](alg3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <figure>\n",
    "  <img src=\"alg1res10.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(Data 1).</figcaption>\n",
    "</figure>\n",
    "   <figure>\n",
    "  <img src=\"alg1res11.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.5).</figcaption>\n",
    "</figure>\n",
    " \n",
    " <figure>\n",
    "  <img src=\"alg1res9.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.2).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible reason for its success__: generating data after learning parameters ensures randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Future Discussion__: \n",
    "    1. Is learning parameters meaningful in VAE? \n",
    "    2. Result of (1,1,0.2) and (1,1,0.5) is similar, this model is not sensitive to change of parameters. I also tried (0.8,1.2,0.4), but the result is the same as (1,1,0.2). Approaches tried: (1) remove tanh in decoder; (2) increase samples from $10^4$ to $10^5$; (3) change prior of latent variables to Dirichlet Distribution or Gamma Distribution. Performance of the first two approaches didn't improve, but the last one did (See __Model 3__ for more detail.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix C__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model 3 (the best so far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Model 2, outputs of Model 3 is parameters, rather than data. Prior of latent variables changes from standard multivariant normal to dirichlet distirbution Dir(1-1/z_dim,1-1/z_dim,1-1/z_dim). To optimize parameters, minimize loss function: <br />\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~$MSE(p,p$^{\\prime\\prime}$)+KL(Z||Dir($\\hat{\\alpha},...,\\hat{\\alpha}))$, where $\\hat{\\alpha}=1-1/$z_dim <br />\n",
    "Detail shown graphical model below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg4](alg4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__:\n",
    "<figure>\n",
    "  <img src=\"alg2res6.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(Data 1).</figcaption>\n",
    "</figure>\n",
    "<figure>\n",
    "  <img src=\"alg2res5.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.5).</figcaption>\n",
    "</figure>\n",
    "<figure>\n",
    "  <img src=\"alg2res4.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.2).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible reason for its success__: generating data after learning parameters ensures randomness. Using Dirichlet Distribution as prior of lattent variables achieves better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Further Discussion__: 1. the performance improved, but not enough. For example, if training dataset is Dir(0.4,0.8,1.2), outputs are around (0.6007, 1.2494, 1.3129). How to improve? (tried to use Gamma Distribution as a prior, it doesn't help.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix D__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Model 1, change loss function to <br />\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ $\\sum_{k=1}^{batch}\\sum_{j=1}^{datapoints}(\\alpha_1-1)log(p^{\\prime\\prime(kj)}_1)+(\\alpha_2-1)log(p^{\\prime\\prime(kj)}_2)+(\\alpha_3-1)log(p^{\\prime\\prime(kj)}_3)$\n",
    "\n",
    "Detail shown in graphical model below (same as Model 1):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg1](alg1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <figure>\n",
    "  <img src=\"alg1res4.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(One dot for any training data).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Problem__: Result is one dot whatever dataset is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible reason for result__: the data that can minimizing this loss function is mode, so this dot is mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix E__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Model 1, I added a regularization term to loss function, which can make outputs from one sample different from outputs from other samples. The loss function is: <br />\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~$ $MSE(p,p^{\\prime\\prime})+KL(Z||N(0,1))-a\\sum_{k=1}^{batch}MSE(p^{\\prime\\prime(k)},p^{\\prime\\prime(-k)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__  (a=1000): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <figure>\n",
    "  <img src=\"alg1res6.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(Data 1).</figcaption>\n",
    "</figure>\n",
    "   <figure>\n",
    "  <img src=\"alg1res7.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.5).</figcaption>\n",
    "</figure>\n",
    "   <figure>\n",
    "  <img src=\"alg1res5.png\" alt=\"my alt text\" width=300/>\n",
    "  <img src=\"alg1res5.1.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.2).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Problem__: Although datapoints are more dispersed after adding regularization term, it is not enough to generate new data from this VAE. Also,according to results with training dataset Dir(1,1,0.2), results are not stable. A big \"a\", like 1000, can decrease the difference between MSE term and regularization term significantly, but the performance based on a=1000 is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible reason for result__: I only use a parameter \"a\" to scale regularization term, a more suitable scaling method should be used. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix F__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change prior of latent variables from multivariant standard normal distribution to dirichlet distribution. Train the model by minimizing <br />\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ $MSE(p,p^{\\prime\\prime})+KL(Z||Dir(\\hat{\\alpha},...,\\hat{\\alpha}))$ <br /> where $\\hat{\\alpha}$=1-1/z_dim\n",
    "\n",
    "Detail shown in graphical model below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg2](alg2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg2res2.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(Data 1).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg2res3.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.5).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg2res1.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(1,1,0.2).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Problem__: datapoints generated are too dense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible Reason for Result__:this model only learns concentration of training datapoints, and ignores sparity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix G__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Model 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Model 2, change loss function to <br />\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~$$\\sum_{k=1}^{batch}\\sum_{j=1}^{datapoints}log(\\Gamma(\\sum_{i}\\alpha^{kj}_i))+\\sum_{i}log(\\Gamma(\\alpha^{kj}_i))+\\sum_{i}(\\alpha^{kj}_i-1)log(p^{kj}_i)$ <br />\n",
    "Graphical model is shown as below (same as Model 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg3](alg3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</figure>\n",
    "   <figure>\n",
    "  <img src=\"alg1res8.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(for all data).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Problem of this method__: Whatever training dataset, result is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible reason for result__: 3 dimensional parameter outputs explode to their maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix H__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Model 3, change loss function to <br />\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~$$\\sum_{k=1}^{batch}\\sum_{j=1}^{datapoints}log(\\Gamma(\\sum_{i}\\alpha^{kj}_i))+\\sum_{i}log(\\Gamma(\\alpha^{kj}_i))+\\sum_{i}(\\alpha^{kj}_i-1)log(p^{kj}_i)$ <br />\n",
    "Details shown in graphical model below (same as Model 8):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg4](alg4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Result__:\n",
    "    <figure>\n",
    "  <img src=\"alg2res9.png\" alt=\"my alt text\" width=300/>\n",
    "  <figcaption>(for all dataset).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Problem of this method__: Whatever training dataset, result is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Possible reason for result__: 3 dimensional parameter outputs explode to their maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Code__ provided in __Appendix I__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods I haven't tried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "Reference https://openreview.net/forum?id=Hkex2a4FPr introduces a method that can fill triangle visualization of dirichlet distribution in text setting, but it is introduced given positive and negative text sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "Output only parameters with dimensionality 3, instead of dimensionality 3*200=600. And generate 200 datapoints from $(p_1,p_2,p_3)\\sim Dir(\\alpha^\\prime_1,\\alpha^\\prime_2,\\alpha^\\prime_3)$. Details shown in graphical model below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alg5](alg5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 \n",
    "use 3 VAEs for each entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Appendix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), '../'))\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "from scipy.stats import dirichlet\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class Dirdata(Dataset):\n",
    "    def __init__(self, dataPoints=20, samples=10000,\n",
    "                        seed=np.random.randint(20),indicate=0,num_param=3):\n",
    "        self.dataPoints = dataPoints\n",
    "        self.samples = samples\n",
    "        self.seed = seed\n",
    "        self.Max_Points = samples * dataPoints\n",
    "        self.indicate=indicate\n",
    "        self.num_param=num_param\n",
    "        np.random.seed(self.seed)\n",
    "        self.evalPoints, self.data, self.occure = self.__simulatedata__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "    \n",
    "    def __getitem__(self, idx=0):\n",
    "        return(self.evalPoints, self.data[idx],self.occure[idx])\n",
    "    \n",
    "    def __simulatedata__(self):\n",
    "        # Dir(alpha,alpha,alpha), alpha~Uniform(0.5,2)\n",
    "        if (self.indicate==0):\n",
    "            #generate alpha\n",
    "            alpha=np.random.uniform(0.5,2,self.samples)\n",
    "            #repeat alpha\n",
    "            alpha=np.array([alpha]*self.num_param).transpose()\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta \n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha[idx,:],self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta[idx][idy,:],size=1)\n",
    "            \n",
    "            return (alpha ,theta, occurrence)\n",
    "\n",
    "        #Dir(alpha,alpha,alpha), alpha has equally spaced grid\n",
    "        if (self.indicate==1):\n",
    "            #generate alpha\n",
    "            alpha=np.linspace(0.5, 2,self.samples)\n",
    "            #repeat alpha\n",
    "            alpha=np.array([alpha]*self.num_param).transpose()\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta \n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha[idx,:],self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta[idx][idy,:],size=1)\n",
    "            \n",
    "            return (alpha ,theta, occurrence)\n",
    "\n",
    "        # Dir(alpha1,alpha2,alpha3), alpha1,alpha2,alpha3~Uniform(0.5,2)\n",
    "        if (self.indicate==2):\n",
    "            #generate alpha\n",
    "            alpha=np.random.uniform(0.5,2,(self.samples,self.num_param))\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta \n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha[idx,:],self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta[idx][idy,:],size=1)\n",
    "            \n",
    "            return (alpha ,theta, occurrence)\n",
    "\n",
    "        # Dir(alpha1,alpha2,alpha3), alpha1,alpha2,alpha3 have equally spaced grids\n",
    "        if (self.indicate==3):\n",
    "            #generate alpha\n",
    "            alpha=np.linspace(0.5, 2, self.samples*self.num_param)\n",
    "            #shuffle alpha\n",
    "            alpha = np.random.choice(alpha, (self.samples,self.num_param))\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta\n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha[idx,:],self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta[idx][idy,:],size=1)\n",
    "            \n",
    "            return (alpha ,theta, occurrence)\n",
    "\n",
    "        # Dir(1,1,0.2)\n",
    "        if (self.indicate==4):\n",
    "            alpha=np.array([1,1,0.5])\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta\n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha,self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta[idx][idy,:],size=1)\n",
    "\n",
    "            return (alpha ,theta, occurrence)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ds =Dirdata(dataPoints=200, samples=3, indicate=4,num_param=3)\n",
    "    dataloader = DataLoader(ds, batch_size=1, shuffle=True)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    for no,dt in enumerate(dataloader):\n",
    "        df=pd.DataFrame(dt[1][0],columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Appendix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from Dirdata import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = self.linear1(x)\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softmax(dim=2)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = self.linear1(x)\n",
    "        # hidden1 is of shape [batch_size, hidden_dim2]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim1]\n",
    "        out1 = self.out1(hidden2)\n",
    "        #reshape output for further procedure\n",
    "        out1 = torch.reshape(out1,(x.shape[0],dataPoints,num_param))\n",
    "        #ensure sum of 3 elements to be 1\n",
    "        pred = self.out2(out1)\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return pred\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        return generated_x, z_mu,z_sd\n",
    "\n",
    "def calculate_loss(reconstructed1,target, mean, log_sd):\n",
    "    RCL = F.mse_loss(reconstructed1, target, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=200\n",
    "    batch_size = 50\n",
    "    hidden_dim1 = 300\n",
    "    hidden_dim2 = 250\n",
    "    z_dim = 150\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds =Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(20)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE (flattened)\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu, z_sd = model(x_)\n",
    "            #change dimensionality for computing loss function\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #loss \n",
    "            loss=calculate_loss(reconstructed_x1,x_,z_mu,z_sd)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "                \n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(5, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        sampled_y = model.decoder(z)\n",
    "    \n",
    "    for no, y in enumerate(sampled_y):\n",
    "        #create a dataframe\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        #plot\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Appendix C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from DirData1 import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softplus(beta=1,threshold=20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        out1 = torch.tanh(self.out1(hidden2))\n",
    "        # make outputs be positive\n",
    "        out2 = self.out2(out1)\n",
    "        out2 = torch.reshape(out2,(x.shape[0],dataPoints,num_param))\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return out2\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def reparameterize1(self,x,beta,dataPoints,num_param):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        # sample from the distribution having parameter outputs\n",
    "            # reparameterize\n",
    "        u = torch.rand((x.shape[0],dataPoints,num_param))\n",
    "        x = x.reshape((x.shape[0],dataPoints,num_param))\n",
    "        y = torch.zeros((x.shape[0],dataPoints,num_param))\n",
    "        for idx in range(x.shape[0]):\n",
    "            v = 1/beta*((torch.mul(torch.mul(u[idx],x[idx]),torch.exp(torch.lgamma(x[idx])))).pow(1/x[idx]))\n",
    "            y[idx]=torch.mul(v,1/torch.transpose(torch.sum(v,1).repeat(x[idx].shape[1],1),0,1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x,beta,dataPoints,num_param):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        pred = self.reparameterize1(generated_x,beta,dataPoints,num_param)\n",
    "        return pred, z_mu,z_sd\n",
    "\n",
    "def calculate_loss(reconstructed1, target, mean, log_sd):\n",
    "\n",
    "    RCL = F.mse_loss(reconstructed1, target, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=300\n",
    "    batch_size = 50\n",
    "    hidden_dim1 = 200\n",
    "    hidden_dim2 = 150\n",
    "    z_dim =100\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "    beta=1\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds = Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(50)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu,z_sd = model(x_,beta,dataPoints,num_param)\n",
    "            #change dimension\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #loss \n",
    "            loss=calculate_loss(reconstructed_x1,x_,z_mu,z_sd)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(5, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        alpha = model.decoder(z)\n",
    "    alpha=alpha.detach()\n",
    "    sampled_y=np.zeros((5,dataPoints,num_param))\n",
    "    #generate dirichlet distribution data\n",
    "    for idx in range(5):\n",
    "        for idy in range(dataPoints):\n",
    "            sampled_y[idx][idy,:]=np.random.dirichlet(alpha[idx][idy,:])\n",
    "    print(alpha)        \n",
    "    for no, y in enumerate(sampled_y):\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Appendix D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from DirData1 import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softplus(beta=1,threshold=20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        out1 = torch.tanh(self.out1(hidden2))\n",
    "        # make outputs be positive\n",
    "        out2 = self.out2(out1)\n",
    "        out2 = torch.reshape(out2,(x.shape[0],dataPoints,num_param))\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return out2\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def reparameterize1(self,x,beta,dataPoints,num_param):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        # sample from the distribution having parameter outputs\n",
    "            # reparameterize\n",
    "        u = torch.rand((x.shape[0],dataPoints,num_param))\n",
    "        x = x.reshape((x.shape[0],dataPoints,num_param))\n",
    "        y = torch.zeros((x.shape[0],dataPoints,num_param))\n",
    "        for idx in range(x.shape[0]):\n",
    "            v = 1/beta*((torch.mul(torch.mul(u[idx],x[idx]),torch.exp(torch.lgamma(x[idx])))).pow(1/x[idx]))\n",
    "            y[idx]=torch.mul(v,1/torch.transpose(torch.sum(v,1).repeat(x[idx].shape[1],1),0,1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x,beta,dataPoints,num_param):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        pred = self.reparameterize1(generated_x,beta,dataPoints,num_param)\n",
    "        return pred, z_mu,z_sd\n",
    "\n",
    "def calculate_loss(reconstructed1, target, mean, log_sd):\n",
    "\n",
    "    RCL = F.mse_loss(reconstructed1, target, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=300\n",
    "    batch_size = 50\n",
    "    hidden_dim1 = 200\n",
    "    hidden_dim2 = 150\n",
    "    z_dim =100\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "    beta=1\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds = Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(50)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu,z_sd = model(x_,beta,dataPoints,num_param)\n",
    "            #change dimension\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #loss \n",
    "            loss=calculate_loss(reconstructed_x1,x_,z_mu,z_sd)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(5, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        alpha = model.decoder(z)\n",
    "    alpha=alpha.detach()\n",
    "    sampled_y=np.zeros((5,dataPoints,num_param))\n",
    "    #generate dirichlet distribution data\n",
    "    for idx in range(5):\n",
    "        for idy in range(dataPoints):\n",
    "            sampled_y[idx][idy,:]=np.random.dirichlet(alpha[idx][idy,:])\n",
    "    print(alpha)        \n",
    "    for no, y in enumerate(sampled_y):\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Appendix E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from DirData1 import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softmax(dim=2)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        out1 = torch.tanh(self.out1(hidden2))\n",
    "        #reshape output for further procedure\n",
    "        out1 = torch.reshape(out1,(x.shape[0],dataPoints,num_param))\n",
    "        #ensure sum of 3 elements to be 1\n",
    "        pred = self.out2(out1)\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return pred\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        #torch.autograd.set_detect_anomaly(True)\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        return generated_x, z_mu,z_sd\n",
    "\n",
    "def calculate_loss(likeli, mean, log_sd):\n",
    "    RCL = -torch.sum(likeli)\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD + REGU\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=300\n",
    "    batch_size = 5\n",
    "    hidden_dim1 = 39\n",
    "    hidden_dim2 = 25\n",
    "    z_dim =20\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds =Dirdata(dataPoints=dataPoints, samples=samples, indicate=0,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(20)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE (flattened)\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu, z_sd = model(x_)\n",
    "            #change dimension for computing loss function\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #training data\n",
    "            alpha=x[1].float().to(device)\n",
    "            #log-likelihood, ignore irrelavent parts, need to be summed later\n",
    "            likeli=torch.mul(torch.log(reconstructed_x+1e-7),alpha-1)\n",
    "            #loss \n",
    "            loss=calculate_loss(likeli,z_mu,z_sd)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(5, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        sampled_y = model.decoder(z)\n",
    "    \n",
    "    for no, y in enumerate(sampled_y):\n",
    "        #create a dataframe\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        #plot\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Appendix F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from Dirdata import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = self.linear1(x)\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softmax(dim=2)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = self.linear1(x)\n",
    "        # hidden1 is of shape [batch_size, hidden_dim2]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim1]\n",
    "        out1 = self.out1(hidden2)\n",
    "        #reshape output for further procedure\n",
    "        out1 = torch.reshape(out1,(x.shape[0],dataPoints,num_param))\n",
    "        #ensure sum of 3 elements to be 1\n",
    "        pred = self.out2(out1)\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return pred\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        return generated_x, z_mu,z_sd\n",
    "\n",
    "#compute mse of output from different samples \n",
    "def meansq(X):\n",
    "    meansq=torch.zeros(X.shape[1],X.shape[1])\n",
    "    for idx in range(X.shape[1]):\n",
    "        for idy in range(X.shape[1]):\n",
    "            meansq[idx,idy]=F.mse_loss(X[idx,:],X[idy,:], reduction='sum')\n",
    "    return(torch.sum(meansq)/2)\n",
    "\n",
    "def calculate_loss(reconstructed1,target, mean, log_sd,a,meansqsum):\n",
    "    REGU = -a*meansqsum\n",
    "    RCL = F.mse_loss(reconstructed1, target, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD+REGU\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=200\n",
    "    batch_size = 50\n",
    "    hidden_dim1 = 300\n",
    "    hidden_dim2 = 250\n",
    "    z_dim = 150\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "    #parameter multiplied to regularization term\n",
    "    a=1000\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds =Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(20)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE (flattened)\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu, z_sd = model(x_)\n",
    "            #compute regularization term\n",
    "            meansqsum=0\n",
    "            for j in range(batch_size):\n",
    "                meansqsum=meansqsum+meansq(reconstructed_x[j])\n",
    "            #change dimensionality for computing loss function\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #loss \n",
    "            loss=calculate_loss(reconstructed_x1,x_,z_mu,z_sd,a,meansqsum)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(5, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        sampled_y = model.decoder(z)\n",
    "    \n",
    "    for no, y in enumerate(sampled_y):\n",
    "        #create a dataframe\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        #plot\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Appendix G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from Dirdata import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "import math\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.linear3 = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.softplus1 = torch.nn.Softplus(beta=1, threshold=20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        alpha = self.linear3(hidden2)\n",
    "        # ensure outputs are positive\n",
    "        alpha = self.softplus1(alpha)\n",
    "        # alpha is of shape [batch_size, z_dim]\n",
    "        return alpha\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.linear3 = nn.Linear(hidden_dim1, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = self.linear1(x)\n",
    "        # hidden1 is of shape [batch_size, hidden_dim2]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim1]\n",
    "        out1 = self.linear3(hidden2)\n",
    "        #reshape output for further procedure\n",
    "        out1 = torch.reshape(out1,(x.shape[0],dataPoints,num_param))\n",
    "        #ensure sum of 3 elements to be 1\n",
    "        pred = torch.zeros((x.shape[0],dataPoints,num_param))\n",
    "        for idx in range(x.shape[0]):\n",
    "            pred[idx] = torch.mul(out1[idx],1/torch.transpose(torch.sum(out1[idx],1).repeat(num_param,1),0,1))\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return pred\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim,beta):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "        self.beta = beta\n",
    "\n",
    "    def reparameterize(self, alpha,beta):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        # sample from the dirichlet distribution having latent parameters alpha\n",
    "            # reparameterize\n",
    "        u = torch.rand(alpha.shape)\n",
    "        v = 1/beta*((torch.mul(torch.mul(u,alpha),torch.exp(torch.lgamma(alpha)))).pow(1/alpha))\n",
    "        v = torch.mul(v,1/torch.transpose(torch.sum(v,1).repeat(alpha.shape[1],1),0,1))\n",
    "        return v\n",
    "\n",
    "    def forward(self, x,beta):\n",
    "        # encode\n",
    "        alpha = self.encoder(x)\n",
    "        # reparameterize\n",
    "        v = self.reparameterize(alpha,beta)\n",
    "        # decode\n",
    "        generated_x = self.decoder(v)\n",
    "        return generated_x, alpha, v\n",
    "\n",
    "def calculate_loss(reconstructed1,target, alpha):\n",
    "    RCL = F.mse_loss(reconstructed1, target, reduction='sum')\n",
    "    KLD = torch.sum(torch.lgamma(alpha),1)-torch.sum(torch.tensor(([math.lgamma(1-1/alpha.shape[1])])).repeat(alpha.shape[0]*alpha.shape[1]).reshape(alpha.shape[0],alpha.shape[1]),1)+torch.sum((torch.tensor(([math.lgamma(1-1/alpha.shape[1])])).repeat(alpha.shape[0]*alpha.shape[1]).reshape(alpha.shape[0],alpha.shape[1])-alpha)*torch.digamma(torch.tensor([1-1/alpha.shape[1]])),1)\n",
    "    KLD = torch.sum(KLD)\n",
    "    return RCL , KLD\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints = 200\n",
    "    batch_size = 5\n",
    "    hidden_dim1 = 150\n",
    "    hidden_dim2 = 100\n",
    "    z_dim = 50\n",
    "    samples = 1000\n",
    "    num_param = 3\n",
    "    input_dim = dataPoints*num_param\n",
    "    beta = 1\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim,beta)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds =Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(20)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE (flattened)\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, alpha, v = model(x_,beta)\n",
    "            #change dimensionality for computing loss function\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #loss \n",
    "            rcl,kdl=calculate_loss(reconstructed_x1,x_,alpha)\n",
    "            loss=rcl+kdl\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    u_ = torch.rand(5,z_dim)\n",
    "    alpha_ = torch.tensor([1-1/z_dim]).repeat(z_dim*5).reshape(5,z_dim)\n",
    "    v_ = 1/beta*((torch.mul(torch.mul(u_,alpha_),torch.exp(torch.lgamma(alpha_)))).pow(1/alpha_))\n",
    "    v_ = torch.mul(v_,1/torch.transpose(torch.sum(v_,1).repeat(z_dim,1),0,1))\n",
    "    # random draw\n",
    "    with torch.no_grad():\n",
    "        sampled_y = model.decoder(v_)\n",
    "\n",
    "    for no, y in enumerate(sampled_y):\n",
    "        #create a dataframe\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        #plot\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Appendix H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from DirData1 import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softplus(beta=1,threshold=20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        out1 = torch.tanh(self.out1(hidden2))\n",
    "        # make outputs be positive\n",
    "        out2 = self.out2(out1)\n",
    "        out2 = torch.reshape(out2,(x.shape[0],dataPoints,num_param))\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return out2\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def reparameterize1(self,x,beta,dataPoints,num_param):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        # sample from the distribution having parameter outputs\n",
    "            # reparameterize\n",
    "        u = torch.rand((x.shape[0],dataPoints,num_param))\n",
    "        x = x.reshape((x.shape[0],dataPoints,num_param))\n",
    "        y = torch.zeros((x.shape[0],dataPoints,num_param))\n",
    "        for idx in range(x.shape[0]):\n",
    "            v = 1/beta*((torch.mul(torch.mul(u[idx],x[idx]),torch.exp(torch.lgamma(x[idx])))).pow(1/x[idx]))\n",
    "            y[idx]=torch.mul(v,1/torch.transpose(torch.sum(v,1).repeat(x[idx].shape[1],1),0,1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x,beta,dataPoints,num_param):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        pred = self.reparameterize1(generated_x,beta,dataPoints,num_param)\n",
    "        return pred, z_mu,z_sd\n",
    "\n",
    "def calculate_loss(likeli1,likeli2,likeli3, mean, log_sd):\n",
    "\n",
    "    RCL = -(torch.sum(likeli1)+torch.sum(likeli2)+torch.sum(likeli3))/(batch_size*dataPoints)\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=200\n",
    "    batch_size = 500\n",
    "    hidden_dim1 = 100\n",
    "    hidden_dim2 = 75\n",
    "    z_dim =50\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "    beta=1\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds = Dirdata(dataPoints=dataPoints, samples=samples, indicate=0,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(20)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu, z_sd = model(x_,beta,dataPoints,num_param)\n",
    "            #change dimension\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #log-likelihood\n",
    "            likeli1=torch.mul(torch.log(x_),reconstructed_x1-1).reshape(batch_size,dataPoints,num_param)\n",
    "            likeli2=-torch.sum(torch.lgamma(reconstructed_x),2)\n",
    "            likeli3=torch.lgamma(torch.sum(reconstructed_x,2))\n",
    "            #loss \n",
    "            loss=calculate_loss(likeli1,likeli2,likeli3,z_mu,z_sd)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(5, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        alpha = model.decoder(z)\n",
    "    alpha=alpha.detach()\n",
    "    sampled_y=np.zeros((5,dataPoints,num_param))\n",
    "    #generate dirichlet distribution data\n",
    "    for idx in range(5):\n",
    "        for idy in range(dataPoints):\n",
    "            sampled_y[idx][idy,:]=np.random.dirichlet(alpha[idx][idy,:])\n",
    "    print(alpha)       \n",
    "    for no, y in enumerate(sampled_y):\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Appendix I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########problem: output explode to max because it will give max loglikelihood\n",
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from DirData1 import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.linear3 = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.softplus1 = torch.nn.Softplus(beta=1, threshold=20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        alpha = self.linear3(hidden2)\n",
    "        # ensure outputs are positive\n",
    "        alpha = self.softplus1(alpha)\n",
    "        # alpha is of shape [batch_size, z_dim]\n",
    "        return alpha\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softplus(beta=1,threshold=20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = torch.tanh(self.linear2(hidden1))\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        out1 = torch.tanh(self.out1(hidden2))\n",
    "        # ensure outputs are positive\n",
    "        out2 = self.out2(out1)\n",
    "        # reshape output\n",
    "        pred = torch.reshape(out2,(x.shape[0],dataPoints,num_param))\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return pred\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim,beta):\n",
    "        #torch.autograd.set_detect_anomaly(True)\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "        self.beta = beta\n",
    "\n",
    "    def reparameterize(self, alpha,beta):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        # sample from dirichlet distribution having latent parameters alpha1,alpha2,alpha3\n",
    "            # reparameterize\n",
    "        u = torch.rand(alpha.shape)\n",
    "        v = 1/beta*((torch.mul(torch.mul(u,alpha),torch.exp(torch.lgamma(alpha)))).pow(1/alpha))\n",
    "        v = torch.mul(v,1/torch.transpose(torch.sum(v,1).repeat(alpha.shape[1],1),0,1))\n",
    "        return v\n",
    "\n",
    "    def reparameterize1(self,x,beta,dataPoints,num_param):\n",
    "            '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "            '''\n",
    "        # sample from the distribution having parameter outputs\n",
    "            # reparameterize\n",
    "            u = torch.rand((x.shape[0],dataPoints,num_param))\n",
    "            x = x.reshape((x.shape[0],dataPoints,num_param))\n",
    "            y = torch.zeros((x.shape[0],dataPoints,num_param))\n",
    "            for idx in range(x.shape[0]):\n",
    "                v = 1/beta*((torch.mul(torch.mul(u[idx],x[idx]),torch.exp(torch.lgamma(x[idx])))).pow(1/x[idx]))\n",
    "                y[idx]=torch.mul(v,1/torch.transpose(torch.sum(v,1).repeat(x[idx].shape[1],1),0,1))\n",
    "            return y\n",
    "\n",
    "    def forward(self, x,beta,dataPoints,num_param):\n",
    "        # encode\n",
    "        alpha = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(alpha,beta)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        pred = self.reparameterize1(generated_x,beta,dataPoints,num_param)\n",
    "        return pred, alpha\n",
    "\n",
    "def calculate_loss(likeli1,likeli2,likeli3, alpha):\n",
    "    # negative log-likelihood\n",
    "    RCL = -(torch.sum(likeli1)+torch.sum(likeli2)+torch.sum(likeli3))\n",
    "    # KL divergence \n",
    "    KLD=torch.sum(torch.lgamma(alpha),1)-torch.sum(torch.tensor(([math.lgamma(1-1/alpha.shape[1])])).repeat(alpha.shape[0]*alpha.shape[1]).reshape(alpha.shape[0],alpha.shape[1]),1)+torch.sum((torch.tensor(([math.lgamma(1-1/alpha.shape[1])])).repeat(alpha.shape[0]*alpha.shape[1]).reshape(alpha.shape[0],alpha.shape[1])-alpha)*torch.digamma(torch.tensor([1-1/alpha.shape[1]])),1)\n",
    "    KLD = torch.sum(KLD)\n",
    "    return RCL + KLD \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=200\n",
    "    batch_size = 50\n",
    "    hidden_dim1 = 100\n",
    "    hidden_dim2 = 50\n",
    "    z_dim =20\n",
    "    samples = 1000\n",
    "    num_param=3\n",
    "    input_dim = dataPoints*num_param\n",
    "    beta=1\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim,beta)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds = Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(20)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE (flattened)\n",
    "            x_ = x[1].float().to(device).reshape(batch_size,1,-1)[:,0]\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, alpha = model(x_,beta,dataPoints,num_param )\n",
    "            #change dimension for computing loss function\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #log-likelihood\n",
    "            likeli1=torch.mul(torch.log(x_),reconstructed_x1-1).reshape(batch_size,dataPoints,num_param)\n",
    "            likeli2=-torch.sum(torch.lgamma(reconstructed_x),2)\n",
    "            likeli3=torch.lgamma(torch.sum(reconstructed_x,2))\n",
    "            #loss \n",
    "            loss=calculate_loss(likeli1,likeli2,likeli3,alpha)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "            #add to total loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z=torch.distributions.dirichlet.Dirichlet(torch.tensor([1-1/z_dim]).repeat(5*z_dim).reshape(5,z_dim)).sample()\n",
    "    z=z.to(device)# random draw\n",
    "    with torch.no_grad():\n",
    "        alpha = model.decoder(z)\n",
    "    alpha=alpha.detach()\n",
    "    sampled_y=np.zeros((5,dataPoints,num_param))\n",
    "    #generate dirichlet distribution\n",
    "    for idx in range(5):\n",
    "        for idy in range(dataPoints):\n",
    "            sampled_y[idx][idy,:]=np.random.dirichlet(alpha[idx][idy,:])\n",
    "    print(alpha)\n",
    "    for no, y in enumerate(sampled_y):\n",
    "        df=pd.DataFrame(y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
