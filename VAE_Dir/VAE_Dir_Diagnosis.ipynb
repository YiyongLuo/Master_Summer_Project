{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report contains diagnosis of VAE used to generate Dirichlet Distribution. Section 1 explains algorithm of generating training dataset and VAE; Section 2 shows the problem; Section 3 is the diagnosis; Section 4 introduces further diagnosis if slightly change the code; Section 5 proposes 2 possible solutions; Section 6 is appendix for code.\n",
    "\n",
    "In particular, diagnosis in Section 3 and 4 show: firstly, outputs of VAE at the begining of training are comparatively dispersed, but after a few iteration, outputs become dense; secondly, after training, passing data generated from Dirichlet Distribution gives dense outputs as well; thirdly, changing learning rate and dimension of hidden layers doesn't help. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 Data 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw 1 sample: <br /> \n",
    "$~~~~~$$\\alpha \\sim$Uniform(0,2) <br /> \n",
    "$~~~~~$generate random samples ($p^{(i)}_1,p^{(i)}_2,p^{(i)}_3$)$\\sim$Dir($\\alpha,\\alpha,\\alpha$), i=1,...,200 <br /> \n",
    "Repeat $10^4$ times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualization of 1 sample__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"data1.png\" alt=\"my alt text\" width=300/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 Data 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw 1 sample: <br /> \n",
    "$~~~~~$($\\alpha_1,\\alpha_2,\\alpha_3$)=(1,1,0.5) <br /> \n",
    "$~~~~~$generate random samples ($p_1,p_2,p_3$)$\\sim$Dir($\\alpha_1,\\alpha_2,\\alpha_3$)<br /> \n",
    "Repeat $10^4$ times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualization of 200 samples__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"data2.png\" alt=\"my alt text\" width=300/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"diagnosis1.png\" alt=\"my alt text\" width=1000/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden dim1=40, hidden dim2=30, latent dim=20 <br />\n",
    "$z_1,...,z_{dim3}\\sim \\mathcal{N}(0,\\mathbb{1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generated are too dense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"alg1res2.png\" alt=\"my alt text\" width=\"300\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diagnosis (using training data Dir(1,1,0.5), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1 Output of VAE While Training__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"3.1.1.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs at the beginning).</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"3.1.2.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs during training. Outputs keep similar values in rest of training).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.2 After training, pass data from Dir(1,1,0.5) to the whole VAE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"3.2.1.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs after training. Outputs are all the same).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.3 change learning rate__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change learning rate from 0.001 to 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"3.3.1.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs at the beginning).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"3.3.2.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs during training. Outputs keep similar values in rest of training).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Approaches (change back learning rate to 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Change dimensionality of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__change hidden dim 1,hidden dim 2 and latent dim to 7,5,2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.1.1.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs at the beginning).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.1.2.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs during training. Outputs keep similar values in rest of training).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__change hidden dim 1,hidden dim 2 and latent dim to 100,80,60__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.1.3.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs at the beginning).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.1.4.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs during training. Outputs keep similar values in rest of training).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2  Try Dir(1,1.5,0.5,0.7,1.2,1,0.8,1.8,0.2,0.9) as training dataset, which is 10 dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.2.1.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs at the beginning).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.2.2.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs during training. Outputs keep similar values in rest of training).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Change activiation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(1) delete some tanh__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.3.1.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs at the beginning).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"4.3.2.png\" alt=\"my alt text\" width=\"500\"/>\n",
    "<figcaption>(Batches of outputs during training. Outputs keep similar values in rest of training).</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Possible Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Generate parameter of Dirichlet Distribution, instead of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"5.1.1.png\" alt=\"my alt text\" width=\"1000\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) $z_1,...,z_{dim3}\\sim \\mathcal{N}(0,\\mathbb{1})$ <br />\n",
    "(2) Use inverse Gamma CDF: $z_i \\sim Gamma(\\alpha,\\beta)$ for i=1,...,dim3. <br />\n",
    "$~~~~~$$u_1,...,u_{dim3}\\sim Uniform(0,1)$ <br />\n",
    "$~~~~~$$z_1,...,z_{dim3}\\approx \\beta^{-1}(u_1\\alpha\\Gamma (\\alpha))^{1/\\alpha},...,\\beta^{-1}(u_{dim3}\\alpha\\Gamma (\\alpha))^{1/\\alpha}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet as diri\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import gamma, factorial\n",
    "from tqdm import tqdm, trange\n",
    "from Dirdata2 import Dirdata\n",
    "import torch\n",
    "from scipy.stats import multinomial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import os,sys\n",
    "import pystan\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.linear2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.mu = nn.Linear(hidden_dim2, z_dim)\n",
    "        self.sd = nn.Linear(hidden_dim2, z_dim)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        hidden1 = torch.tanh(self.linear1(x))\n",
    "        # hidden1 is of shape [batch_size, hidden_dim1]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim2]\n",
    "        z_mu = self.mu(hidden2)\n",
    "        # z_mu is of shape [batch_size, z_dim]\n",
    "        z_sd = self.sd(hidden2)\n",
    "        # z_sd is of shape [batch_size, z_dim]\n",
    "        return z_mu, z_sd\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "    '''\n",
    "    def __init__(self,z_dim, hidden_dim1, hidden_dim2, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, hidden_dim2)\n",
    "        self.linear2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.out1 = nn.Linear(hidden_dim1, input_dim)\n",
    "        self.out2 = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, z_dim]\n",
    "        hidden1 = self.linear1(x)\n",
    "        # hidden1 is of shape [batch_size, hidden_dim2]\n",
    "        hidden2 = self.linear2(hidden1)\n",
    "        # hidden2 is of shape [batch_size, hidden_dim1]\n",
    "        out1 = self.out1(hidden2)\n",
    "        #ensure sum of 3 elements to be 1\n",
    "        pred = self.out2(out1)\n",
    "        # pred is of shape [batch_size, input_dim]\n",
    "        return pred\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim1, hidden_dim2, input_dim)\n",
    "\n",
    "    def reparameterize(self, z_mu, z_sd):\n",
    "        '''During training random sample from the learned ZDIMS-dimensional\n",
    "           normal distribution; during inference its mean.\n",
    "        '''\n",
    "        if self.training:\n",
    "            # sample from the distribution having latent parameters z_mu, z_sd\n",
    "            # reparameterize\n",
    "            std = torch.exp(z_sd / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            return (eps.mul(std).add_(z_mu))\n",
    "        else:\n",
    "            return z_mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_sd = self.encoder(x)\n",
    "        # reparameterize\n",
    "        x_sample = self.reparameterize(z_mu, z_sd)\n",
    "        # decode\n",
    "        generated_x = self.decoder(x_sample)\n",
    "        return generated_x, z_mu,z_sd\n",
    "\n",
    "def calculate_loss(reconstructed1,target, mean, log_sd):\n",
    "    RCL = F.mse_loss(reconstructed1, target, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_sd - mean.pow(2) - log_sd.exp())\n",
    "    return RCL + KLD\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ###### intializing data and model parameters\n",
    "    dataPoints=200\n",
    "    batch_size = 5\n",
    "    hidden_dim1 = 40\n",
    "    hidden_dim2 = 30\n",
    "    z_dim = 10\n",
    "    samples = 10000\n",
    "    num_param=3\n",
    "    input_dim = 3\n",
    "\n",
    "    model = VAE(input_dim, hidden_dim1, hidden_dim2, z_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    model = model.to(device)\n",
    "    \n",
    "    ###### creating data\n",
    "    ds =Dirdata(dataPoints=dataPoints, samples=samples, indicate=4,num_param=num_param)\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    ###### train\n",
    "    t = trange(50)\n",
    "    for e in t:\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i,x in enumerate(train_dl):\n",
    "            #input for VAE (flattened)\n",
    "            x_ = x[1].float().to(device)\n",
    "            #make gradient to be zero in each loop\n",
    "            optimizer.zero_grad()\n",
    "            #get output\n",
    "            reconstructed_x, z_mu, z_sd = model(x_)\n",
    "            print(reconstructed_x)\n",
    "            #change dimensionality for computing loss function\n",
    "            reconstructed_x1=reconstructed_x.reshape(batch_size,1,-1)[:,0]\n",
    "            #loss \n",
    "            loss=calculate_loss(reconstructed_x1,x_,z_mu,z_sd)\n",
    "            #compute gradient\n",
    "            loss.backward() \n",
    "            #if gradient is nan, change to 0\n",
    "            for param in model.parameters():\n",
    "                param.grad[param.grad!=param.grad]=0\n",
    "                \n",
    "            #add to toal loss\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step() # update the weigh\n",
    "        t.set_description(f'Loss is {total_loss/(samples*dataPoints):.3}')\n",
    "    \n",
    "    ###### Sampling 5 draws from learnt model\n",
    "    model.eval() # model in eval mode\n",
    "    z = torch.randn(200, z_dim).to(device) # random draw\n",
    "    with torch.no_grad():\n",
    "        sampled_y = model.decoder(z)\n",
    "    df=pd.DataFrame(sampled_y,columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "    fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), '../'))\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "from scipy.stats import dirichlet\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class Dirdata(Dataset):\n",
    "    def __init__(self, dataPoints=20, samples=10000,\n",
    "                        seed=np.random.randint(20),indicate=0,num_param=3):\n",
    "        self.dataPoints = dataPoints\n",
    "        self.samples = samples\n",
    "        self.seed = seed\n",
    "        self.Max_Points = samples * dataPoints\n",
    "        self.indicate=indicate\n",
    "        self.num_param=num_param\n",
    "        np.random.seed(self.seed)\n",
    "        self.evalPoints, self.data, self.data1,self.occure = self.__simulatedata__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "    \n",
    "    def __getitem__(self, idx=0):\n",
    "        return(self.evalPoints, self.data[idx],self.data1[idx],self.occure[idx])\n",
    "    \n",
    "    def __simulatedata__(self):\n",
    "        # Dir(alpha,alpha,alpha), alpha~Uniform(0.5,2)\n",
    "        if (self.indicate==0):\n",
    "            #generate alpha\n",
    "            alpha=np.random.uniform(0.5,2,self.samples)\n",
    "            #repeat alpha\n",
    "            alpha=np.array([alpha]*self.num_param).transpose()\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta \n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha[idx,:],self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta1 = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta1[idx][idy,:],size=1)\n",
    "            occurrence =occurrence.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            return (alpha ,theta,theta1, occurrence)\n",
    "\n",
    "        \n",
    "        # Dir(1,1,0.2)\n",
    "        if (self.indicate==4):\n",
    "            alpha=np.array([1,1,0.2])\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta\n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha,self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta1 = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta1[idx][idy,:],size=1)\n",
    "            occurrence=occurrence.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            return (alpha ,theta, theta1,occurrence)\n",
    "\n",
    "        \n",
    "        if (self.indicate==5):\n",
    "            alpha=np.array([1,1.5,0.5,0.7,1.2,1,0.8,1.8,0.2,0.9])\n",
    "            #initialize theta and counts (counts are only used in inference, not training)\n",
    "            theta = np.zeros((self.samples,self.dataPoints,self.num_param))\n",
    "            occurrence = np.zeros((self.samples, self.dataPoints,self.num_param))\n",
    "            #generate theta\n",
    "            for idx in range(self.samples):\n",
    "                #generate theta from dirichlet distr\n",
    "                theta[idx]=np.random.dirichlet(alpha,self.dataPoints)\n",
    "            #shuffle theta\n",
    "            theta =theta.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            theta=shuffle(theta, random_state=0)\n",
    "            theta1 = theta.reshape(self.samples,self.dataPoints,self.num_param)\n",
    "            #generate counts\n",
    "            for idx in range(self.samples):\n",
    "                for idy in range(self.dataPoints):\n",
    "                    occurrence[idx][idy,:]=np.random.multinomial(50,theta1[idx][idy,:],size=1)\n",
    "            occurrence=occurrence.reshape(self.samples*self.dataPoints,self.num_param)\n",
    "            return (alpha ,theta, theta1,occurrence)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ds =Dirdata(dataPoints=200, samples=1, indicate=0,num_param=3)\n",
    "    dataloader = DataLoader(ds, batch_size=1, shuffle=True)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    for no,dt in enumerate(dataloader):\n",
    "        df=pd.DataFrame(dt[2].reshape(200,3),columns=['$\\\\theta_1$', '$\\\\theta_2$', '$\\\\theta_3$'])\n",
    "        fig =px.scatter_ternary(df, a='$\\\\theta_1$', b='$\\\\theta_2$', c='$\\\\theta_3$',title=\"Dirichlet Distribution Visualization\")\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
